{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dcb4c-c4c4-4a8b-bf96-af793957a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import time \n",
    "\n",
    "ARTIST_BB = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a5172-d8e7-4f6f-8329-7f9dc1b9cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape billboard site given artist name \n",
    "def artist_billboard(artist_name):\n",
    "    # convert artist name to - if spaces\n",
    "    artist_name = artist_name.lower()\n",
    "    artist_name = artist_name.replace(' ', '-')\n",
    "    if artist_name in ARTIST_BB.keys():\n",
    "        return ARTIST_BB[artist_name]\n",
    "    else:\n",
    "        start = time.time()\n",
    "        base = 'https://www.billboard.com/artist/'\n",
    "        url = base + artist_name\n",
    "        page = requests.get(url)\n",
    "        if page.reason == \"Not Found\":\n",
    "            ARTIST_BB[artist_name] = 0\n",
    "            return 0\n",
    "        else:\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            top_100 = soup.find_all(\"div\", class_ =\"artist-chart-history-sticky-wrapper lrv-u-position-relative\")\n",
    "            if len(top_100) > 0:\n",
    "                text = top_100[0].text.strip('\\n').strip('\\t').strip().split('\\t')[0]\n",
    "                if text == \"Billboard Hot 100â„¢\":\n",
    "                    results = soup.find_all(\"span\", class_=\"c-span a-font-primary-bold u-font-size-34 u-line-height-120 u-letter-spacing-0063 artist-stat-3\")\n",
    "                    if len(results) < 1: \n",
    "                        ARTIST_BB[artist_name] = 0\n",
    "                        end = time.time()\n",
    "                        #print(end - start) \n",
    "                        return 0 \n",
    "                    hits = int(results[0].text.strip())\n",
    "                    if hits > 1:\n",
    "                        ARTIST_BB[artist_name] = 1\n",
    "                        end = time.time()\n",
    "                        #print(end - start) \n",
    "                        return 1\n",
    "            end = time.time()\n",
    "            #print(end - start) \n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c533479-da46-482a-86d9-f93e8ec1f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data CSVs into a single dataframe\n",
    "# Collect data CSVs into a single dataframe\n",
    "dfs = []\n",
    "directory = \"dataset\" \n",
    "#Spins-search-results-9-23-23-3-22-24-for-WRUV\n",
    "df = pd.read_csv(\"dataset/Spins-search-results-9-23-23-3-22-24-for-WRUV.csv\")\n",
    "df.sort_values(\"Date-time\", inplace=True, ignore_index=True)\n",
    "# convert Date-time to date time\n",
    "# filter for values in the last year \n",
    "df.drop([\"Playlist Category\", \"Playlist Duration\", \"DJ Email\", \"Date-time\", \"Composer\"], axis=1, inplace=True)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df[df[\"Date\"] >= \"01-01-2024\"]\n",
    "# Drop columns that we already know we don't need\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387202e-050a-4c2b-bd3c-5254a9767ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "splits = int(len(df) / 10)\n",
    "print(splits)\n",
    "print(type(splits))\n",
    "for i in range(10):\n",
    "    print(i, (i*splits), ((i+1)*splits))\n",
    "    slice = df.iloc[(i*splits): ((i+1)*splits), :]\n",
    "    slice['artistBB'] = slice['Artist'].apply(artist_billboard)\n",
    "    dfs.append(slice)\n",
    "    slice.to_csv(\"slice\" + str(i) + \".csv\")\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379adf43-6954-4f1b-a7e1-db8bed14eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "df.to_csv(\"2024-with-billboard-artists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e822175-2414-476b-95ab-456b1ce015da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the null values from the boolean columns New and Local\n",
    "df[\"New\"] = df[\"New\"].map({\"N\": 1, np.nan: 0})\n",
    "df[\"Local\"] = df[\"Local\"].map({\"L\": 1, np.nan: 0})\n",
    "\n",
    "# Since there are only 56 instances where artist, song, or release are null,\n",
    "# we feel comfortable dropping those instances\n",
    "df = df.dropna(subset=[\"Artist\", \"Song\", \"Release\"])\n",
    "\n",
    "# Count null values again\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e9d2e-d564-4538-a588-8ce5a3245d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def billboard_songs(artist_name, song_name):\n",
    "    # convert artist name to - if spaces\n",
    "    artist_name = artist_name.lower()\n",
    "    artist_name = artist_name.replace(' ', '-')\n",
    "    base = 'https://www.billboard.com/artist/'\n",
    "    url = base + artist_name\n",
    "    page = requests.get(url)\n",
    "    if page.reason == \"Not Found\":\n",
    "        return 0\n",
    "    else:\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find_all(\"span\",\n",
    "                                class_=\"c-span a-font-primary-bold u-font-size-34 u-line-height-120 u-letter-spacing-0063 artist-stat-3\")\n",
    "        if len(results) < 1:\n",
    "            return 0\n",
    "        hits = int(results[0].text.strip())\n",
    "        if hits > 1:\n",
    "            url = url + \"/chart-history/hsi\"\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            songs = soup.find_all(\"div\", class_ =\"o-chart-results-list__item // lrv-u-flex lrv-u-flex-direction-column lrv-u-flex-grow-1 lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light lrv-u-padding-lr-2 lrv-u-padding-lr-1@mobile-max lrv-u-padding-tb-050@mobile-max\")\n",
    "            for i in range(hits):\n",
    "                song = songs[i].text.strip('\\n')\n",
    "                song = song.strip('\\t')\n",
    "                song = song.strip()\n",
    "                song = song.split('\\t')[0]\n",
    "                if song_name == song:\n",
    "                    print(f'billboard! {song_name} by {artist_name}')\n",
    "                    return 1\n",
    "        return 0\n",
    "#smaller['songBB'] = smaller[['Artist', 'Song']].apply(artist_billboard)\n",
    "#smaller\n",
    "\n",
    "\n",
    "#df['New_Column'] = df.apply(lambda row: custom_function(row['A'], row['B']), axis=1)\n",
    "# apply this only to songs for which billboard = 1, if billboard = 0, this is = 0 \n",
    "#df['songBB'] = df[df['artistBB' == 0]\n",
    "#df['songBB'].iloc\n",
    "#df['songBB'] = df.apply(lambda row: billboard_songs(row['Artist'], row['Song']), axis=1)\n",
    "#df\n",
    "# set them all to 0\n",
    "# then run songBB to replace with 1 if artistBB is 1 and song matches web scrapping \n",
    "df['songBB'] = 0\n",
    "#df['songBB'] = df.apply(lambda row: billboard_songs(row['Artist'], row['Song']), axis=1)\n",
    "\n",
    "df.loc[df['artistBB'] == 1, 'songBB'] = df.apply(lambda row: billboard_songs(row['Artist'], row['Song']), axis=1)\n",
    "# next, run spotify and save it as csv \n",
    "df.to_csv(\"2024-all-billboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8c07c-eeee-4b40-bf38-6f0defd4d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spotify_connect():\n",
    "    # technically insecure to have client secret displayed like this (environment variable)\n",
    "    CLIENT_ID = '344d3b062e344710a5bdb8427358a31d'\n",
    "    CLIENT_SECRET = '9f886dde51184f989b1aff4f5ffb21f8'\n",
    "    AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    auth_manager = SpotifyClientCredentials(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        requests_session=True)\n",
    "\n",
    "    sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "    # this is our connection which we will need for any future query \n",
    "    return sp\n",
    "    \n",
    "# just making this global for effeciency (no need to reaccess every time) \n",
    "sp = spotify_connect()\n",
    "\n",
    "# next step: instead of returning result_string, return dictionary of values OR empty dictionary of NAs?\n",
    "def spotify_search_song(artist_name, song_name):\n",
    "    results = sp.search(q='track:' + song_name, type='track', limit=10)\n",
    "    try: \n",
    "        results_title = results['tracks']['items'][0]['name']\n",
    "        results_album = results['tracks']['items'][0]['album']['name']\n",
    "        results_artist = results['tracks']['items'][0]['artists'][0]['name']\n",
    "    except IndexError:\n",
    "        return {}\n",
    "    # if this results title matches our song name and the artist matches our artist, find the audio features and add them (by spotify uri id for song)\n",
    "    i = 0\n",
    "    while (results_artist != artist_name) & (results_title != song_name) & (i < len(results)):\n",
    "        results_title = results['tracks']['items'][i]['name']\n",
    "        results_artist = results['tracks']['items'][i]['artists'][0]['name']\n",
    "        i += 1\n",
    "    if (results_artist == artist_name) & (results_title == song_name):\n",
    "        uri = results['tracks']['items'][i]['id'] \n",
    "        # these are audio features!! like danceability, energy, key, loudness..\n",
    "        # stored in an array of length 1 containing a dictionary (key = audio feature, value = value of that feature)\n",
    "        features = sp.audio_features(uri)\n",
    "        return_val = {'danceability': features[0]['danceability'], 'energy': features[0]['energy'], 'key' : features[0]['energy'],\n",
    "              'loudness': features[0]['loudness'], 'mode': features[0]['mode'], 'speechiness': features[0]['speechiness'],\n",
    "              'acousticness': features[0]['acousticness'], 'instrumentalness': features[0]['instrumentalness'],\n",
    "              'liveness': features[0]['liveness'], 'valence': features[0]['valence'], 'tempo': features[0]['tempo'],\n",
    "              'duration_ms': features[0]['duration_ms']}\n",
    "        result_string =  f'TOP RESULT: {results_title} from {results_album} by {results_artist}. URI: {uri}'\n",
    "        return return_val\n",
    "    return {}\n",
    "\n",
    "# we have slice 0 and 1 rn (ned 2 - 9)\n",
    "for i in range(2, 10):\n",
    "    print(i, (i*splits), ((i+1)*splits))\n",
    "    slice = df.iloc[(i*splits): ((i+1)*splits), :]\n",
    "    slice[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instruemtnalness', 'liveness', 'valence', \n",
    "    'tempo', 'duration_ms']] = slice.apply(lambda row: spotify_search_song(row['Artist'], row['Song']), axis='columns', result_type='expand')\n",
    "    dfs.append(slice)\n",
    "    slice.to_csv(\"slice\" + str(i) + \".csv\")\n",
    "dfs\n",
    "\n",
    "#danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, \n",
    "# valence, tempo, duration_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a3b02-008f-4a96-aefb-b66d8ece9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "df\n",
    "slices = []\n",
    "# right now we have 2 slices, hopefully we will get a lot more \n",
    "for i in range(2):\n",
    "    slices.append(pd.read_csv(f'slice{i}.csv'))\n",
    "small = pd.concat(slices, axis=0)\n",
    "small[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
